runs:
  - name: "gpt-oss-120b-run1"
    engine: "vllm"
    serve:
      model_path: "Scicom-intl/gpt-oss-120b-Malaysian-Reasoning-SFT-v0.1"
      port: 8000
      gpu_memory_utilization: 0.9
      max_model_len: 12000
      max_num_seqs: 256
      dtype: "bfloat16"
      disable_log_requests: true
      enable_expert_parallel: false
      tp_dp_pairs:
        - tp: 4
          dp: 1
          pp: 1
        - tp: 4
          dp: 1
          pp: 1
    bench:
      output_dir: "./benchmark_results"
      context_size: [1024, 2048, 4096, 8192]
      concurrency: [100]
      num_prompts: [100]
      output_len: [128]
